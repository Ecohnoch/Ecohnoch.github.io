---
layout: post
title:  "动态GAN复现(一) GANimation概览、结构、原理与细节"
date:   2019-12-05
categories: 算法与数学
excerpt: 嗯
---
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
  inlineMath: [['$','$'], ['\\(','\\)']],
  processEscapes: true
  },
displayAlign : "left",
TeX: {
            equationNumbers: {
                autoNumber: "all",
                useLabelIds: true
            }
        },
        "HTML-CSS": {
            linebreaks: {
                automatic: true
            },
            scale: 100,
            styles: {
              ".MathJax_Display": {
                "text-align": "left",
                "width" : "auto",
                "margin": "10px 0px 10px 0px !important",
                "background-color": "#f5f5f5 !important",
                "border-radius": "3px !important",
                border:  "1px solid #ccc !important",
                padding: "5px 5px 5px 5px !important"
              },
              ".MathJax": {
                "background-color": "#f5f5f5 !important",
                padding: "2px 2px 2px 2px !important"
              }
            }
        },
        SVG: {
            linebreaks: {
                automatic: true
            }
        }
});
</script>
<!--
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
-->

原创：岐山凤鸣，转载请注明本站域名

GANimation论文地址：https://arxiv.org/abs/1807.09251

原文Github仓库：https://github.com/albertpumarola/GANimation

ps:据说原文的仓库不太好用，可以采用一些其他的复刻版本，我的复刻版本未来放出。


# 开局

这玩意是干嘛的？一句话：开局一张图，生成这张图的动画，如下图所示：

![image](/img/ganimation.png)

输入是一张静止的单张图片，也就是最左边那个，即$$I_{y_r}$$，$$\alpha$$表示目标动作的度，比如上述动作为"微笑"，从0-1分别表示微笑的程度，然后这段连续的动画，就生成了。

所以整个过程都强调两个特点：1. Automatically, 2. Smoothly，这个就非常的强了。

那这么强东西，怎么样我才能拥有一个呢，本次咱就来复现这个东西，我之后要做的一个东西，也是类似这么强的东西，正好也要和这个进行对比。

首先需要引入一个概念，叫做AU (Action Units)，每个AU都表示一个特定的人脸状态，比如对于恐惧这个表情，大概就有以下的AU: Inner Brow Raiser (AU1), Outer Brow Raiser (AU2), Brow Lowerer (AU4) ... Jaw Drop (A26)

他的做法便是将人脸，与给定的这个AU合成，通过这个表情的状态来生成动画，主体的生成方法便是GAN。

# 问题定义

假定一张RGB图像定义为$$I_{y_r} \in \mathbb{R}^{H\times W \times 3}$$，表示任意一张某个人的人脸图，r表示表情arbitrary，定义AU向量$$y_r = (y_1, ..., y_N)^T$$，其中每个是0-1之间进行标准化后的值，表示对应的AU的量级，这个是让模型具备平滑性的重点。

我们的目标就是学习一个映射$$M$$，根据给定的$$y_g$$，使得$$I_{y_r}->I_{y_g}$$，即$$M: (I_{y_r}, y_g) -> I_{y_g}$$

在训练的时候，每次用这个M去训练一个三元组$$\{I_{y_r}^{m}, y_{r}^{m}, y_{g}^{m}\}_{m=1}^{M}$$，其中目标向量$$y_g^m$$是随机生成的。

那么作者的方案即，对生成器，就定义为$$G(I_{y_r}\mid y_g)$$，这个生成器在框架里用了两次，一次是从输入图像$$I_{y_r}$$到$$I_{y_g}$$，第二次是将输出再渲染回去$$I_{y_g}->\hat{I}_{y_r}$$。

并且对判别器D，他用的是基于WGAN-GP的方法，对$$D_I(I_{y_g})$$去评价生成图像的质量，以及$$D_y(I_{y_g})$$去区分前后的生成的表情差异。


# 生成结构

![image](/img/gani_generator.png)

如上便是生成结构，别看画的花里胡哨，实际上内容是很简单的。

先看输入，即是一张真值图片，简单记为real\_face，当然之前说了，输入有两个，还有一个指定的AU，这里记为desired\_au。

然后经过两个共享权重的G，网络是一样的，一个接sigmoid，出来是mask记为fake\_mask，一个接tanh，出来是假图片记为fake\_img。

那么要结合真值图片一起，也就是三部分结合（真值图片，mask，假图），形成一个真值图片里的人带假图表情的那种图像，融合过程如下式子：

```
fake_img, fake_mask = generator(real_face, desired_au)
    // fake_img  ->   generator + tanh
    // fake_mask ->   generator + sigmoid
fake_img_masked = fake_mask * real_face + (1 - fake_mask) * fake_img
```

数学语言表达，则输入为两部分，一个是真值图像$$I_{y_o} \in \mathbb{R}^{H\times W\times 3}$$和一个N长度的向量$$y_f$$表示目标表情AU。

将输入的两者在通道层面concat结合，得到$$(I_{y_o}, y_o})\in \mathbb{R}^{H\times W\times (3+N)$$。

结合的矩阵，输入生成器，将最后的feature map分别经过Sigmoid和tanh，得到假图 C和attention mask A，与真值图像进行三者结合：

$I_{y_f} = (1-A)\cdot C + A\cdot I_{y_o}$

# Loss

loss的公司不咋解释，摆出来看看就行，因为也不好解释，大致就那个意思，写代码也就固定几行就能搞定。

当然自己写论文的时候，这部分就需要好好看，然后好好把自己模型的理论公式推导出来，这步是非常的重要的！所以我这里记录进博客，方便查阅。

### Image Adversarial Loss

对Image adversarial loss，这篇主要是基于WGAN-GP，具体公式如下：

$L_I(G, D_I, I_{y_{y_o}}, y_f) = -\mathbb{E}_{I_{y_o}~\mathbb{P}_o}[D_I(G(I_{y_o}\mid y_f))] + \mathbb{E}_{I_{y_o}~\mathbb{P}_o}[D_I(I_{y_o})] - \lambda_{gp}\mathbb{E}_{\hat{I}~\mathbb{P}_{\hat{I}}}[(\|\bigtriangledown_{\hat{I}}D_I(\hat{I})\|_2-1)^2]$


$$\mathbb{P}_o$$指的是输入图像的数据分布，带hat的I是随机插值分布，最后面那项主要是个惩罚项，lambda是惩罚项系数。

### Attention Loss

公式：

$L_A(G, I_{y_o}, y_f) = \lambda_{TV}L_{TV}(A) + \mathbb{E}_{I_{y_o}~\mathbb{P}}[\|A\|]$

其中$$A=G_A(I_{y_o}\mid y_f)$$，lambda同样是惩罚项系数。

其中:

$L_{TV}(A) = \sum_{i,j}^{H,W}{[(A_{i+1,j}-A_{i,j})^2 + (A_{i,j+1}-A_{i,j})^2]}$


### Conditional Expression Loss

$L_y(G, D_y, I_{y_o}, y_o, y_f) = \mathbb{E}_{I_{y_o}~\mathbb{P}_o}[\|D_y(I_{y_o}) - y_o\|_2^2] + \mathbb{E}_{I_{y_o}~\mathbb{P}_o}[\|D_y(G(I_{y_o\mid y_f}))-y_f\|]$

这里原论文里公式书写有错233，也是第一次在这种知名论文里发现小错误。

### Identity loss

$\mathbb{E}_{I_{y_o}~\mathbb{P}_o}[\|G(G(I_{y_o}\mid y_f)\mid y_o)-I_{y_o}\|_1]$

### Full loss

$L = L_1(G, D_I, I_{y_r}, y_g) + \lambda_y L_y(G, D_y, I_{y_r}, y_r, y_g) + \lambda_A(L_A(G, I_{y_g}, y_r) + L_A(G, I_{y_r}, y_g)) + \lambda_{idt}L_{idt}(G, I_{y_r}, y_r, y_g)$

其中$$\lambda_A, \lambda_y, \lambda_{idt}$$都是超参，和各个问题有关，最后用这个L解决最优化问题：

$G^* = arg\min_G{\max_{D\in \mathbb{D}}{L}}$

在原文的训练细节中，$$\lambda_{gp}=10, \lambda_A = 0.1, \lambda_{TV}=1e-4, \lambda_y=4k, \lambda_{idt}=10$$，模型在Emotionet数据上训练了两天。

# 效果

先放一张和其他模型的对比图：

![image](/img/gani_comparison.png))

从要达到的平滑的效果上来看确实要好一点，关于其他的实验细节的话下一节再说吧。