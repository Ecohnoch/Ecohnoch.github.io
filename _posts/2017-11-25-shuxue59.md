---
layout: post
title:  "深度学习入门（一）TensorFlow系统学习第一篇"
date:   2017-11-02
categories: 算法与数学
excerpt: 嗯
---
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=default" id=""></script>

最近做一个索尼公司的商业项目，要用到深度学习的内容，于是这里记录一些东西，方便查阅..

环境：macOS-10.13.4, Python-3.6, Tensorflow-1.4.1

参考： 《TensorFlow实战》

# 安装TensorFlow

以前写过，参考我的以前的一篇博文：[MacOs下TensorFlow的安装和初探](http://www.ecohnoch.cn/2017/01/20/shuxue17/)

Linux下很方便，直接：

```
$ sudo apt-get install python-pip python-dev
$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
```

就可以了，报错的话根据错误检查一下命令版本更新什么的就好了。

本次项目我准备使用我的阿里云Ubuntu服务器来完成，所以配套的Python和TensorFlow和C++和Linux配置环境都配好了。

然后如果你看到了这里，你是macOS系统而且下了python3.5以上，那么前面的都不用管了，[https://pan.baidu.com/s/1PnZNs3DTri7MvGOSUKx10w](https://pan.baidu.com/s/1PnZNs3DTri7MvGOSUKx10w)，这个网盘里的whl文件下了之后，pip install这个文件就完全ok了。

# TensorFlow模型

TensorFlow中的计算，是一个【有向图】的形式去表现的，每一个运算都是一个节点，运算和运算的连接桥梁叫做边，数据就在这个图里流来流去。流动的数据叫做张量，即Tensor，所以这个模型叫做TensorFlow。

比如一个有向图是这样的：

![image](/img/tf1.png)

中间每个节点都是一个运算，比如MatMul就是矩阵乘法，Add就是加法，ReLU是激励函数，里面的每一条边，都是有向的，代表着数据朝什么方向流动，怎么流动等等。

这个有向图模型，就是以后每一个模型都要涉及的基本概念。

实现它的代码，可以像这个样子写(未补完，不可运行):

```
import tensorflow as tf
b = tf.Variable(tf.zeros([100]))                       # 初始化一个100维向量，均是0，作为b，即bias
W = tf.Variable(tf.random_uniform([784, 100], -1, 1))  # 生成一个784*100维的随机矩阵W
x = tf.placeholder(name = "x")                         # 输入的placeholder
relu = tf.nn.relu(tf.matmul(W, x) + b)                 # 激励函数，也就是弄出来三者之间的一个关系，这里的关系相当于y = W*x + b， W，x，b都是向量或矩阵，然后就可以输入大量的x和y来进行w和b的训练了
C = [....]											   # 根据relu计算Cost
s = tf.Session()									   # 得到结果的时候总是要生成一个会话
for step in range(0, 10):
	input = ....construct 100-D input array.....	   # 为输入创建一个100维的向量，即可以说是一个简单的训练集吧
	result = s.run(C, feed_dict={x: input})			   # 获取Cost，供给输入x
	print(step, result)
```

Session是提供给用户的接口，因为对绝大多数用户，他们都只会执行一个图里的一个子图，反复的计算。

因为计算图反复执行多次，数据即Tensor只是在计算图里过一遍就没了。Variable是个例外，它可以保留在内存里。

# TensorFlow基本的运算操作

类型|示例|
-----|----|---
标量运算| Add、Sub、Mul、Div、Exp、Log、Greater、Less、Equal
向量运算| Concat、Slice、Split、Constant、Rank、Shape、Shuffle
矩阵运算| MatMul、MatrixInverse、MatrixDeterminant
带状态运算| Variable、Assign、AssignAdd
神经网络组件| SoftMax、Sigmoid、ReLU、Convolution2D、MaxPooling
储存、恢复| Save、Restore
队列及同步运算| Enqueue、Dequeue、MutexAcquire、MutexRelease
控制流| Merge、Switch、Enter、Leave、NextIteration

方便以后查阅我展开再写一遍：

* 标量运算
	* Add
	* Sub
	* Mul
	* Div
	* Exp
	* Log
	* Greater
	* Less
	* Equal
* 向量运算
	* Concat
	* Slice
	* Split
	* Constant
	* Rank
	* Shape
	* Shuffie
* 矩阵运算
	* MatMul
	* MatrixInverse
	* MatrixDeterminant
* 带状态运算
	* Variable
	* Assign
	* AssignAdd
* 神经网络组件
	* SoftMax
	* Sigmoid
	* ReLU
	* Convolution2D
	* MaxPooling
* 储存、恢复
	* Save
	* Restore
* 队列及同步运算
	* Enqueue
	* Dequeue
	* MutexAcquire
	* MutexRelease
* 控制流
	* Merge
	* Switch
	* Enter
	* Leave
	* NextIteration






