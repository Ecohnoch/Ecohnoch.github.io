---
layout: post
title:  "语音识别篇（一）SVM进行语音情感分析"
date:   2018-10-01
categories: 算法与数学
excerpt: 嗯
---
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$']]},
        messageStyle: "none"
    });
</script>

保研后咸鱼了很久，这几天重新拿起了学习的动力。

这一篇主要讲的我如何对带情绪标记的一堆语音wav的分类，这里我简单的用了一个SVM去感觉一下，下一篇用CNN。

这一篇尽量讲的非常的简单，因为思路很明确，具体的代码的一些细节看[我的Github仓库](https://github.com/Ecohnoch/Voice-Image-Processing/tree/master/Test_DataSet)，这整个仓库是未来一个大计划的代码，这个单独的文件夹是本节的内容，为了防止人家直接用我的代码，我没有提供数据集，但提供了处理后的csv文件。

# 语音特征提取

如何将一段音频中的特征提取出来，在Github上，已经有前人做过这个工作，即python_speech_features

可以通过这个Page页面的引导去下载这个Library:[https://github.com/jameslyons/python_speech_features](https://github.com/jameslyons/python_speech_features)

需要前置库scipy，具体的用法即：

```
from python_speech_features import mfcc
from python_speech_features import delta
from python_speech_features import logfbank
import scipy.io.wavfile as wav

(rate, sig) = wav.read("xxx.wav")
mfcc_feat = mfcc(sig, rate)
d_mfcc_feat = delta(mfcc_feat, 2)
fbank_feat = logfbank(sig, rate)

print(fbank_feat[1:3,:])
```

想用哪个去提取都行，一般都用的MFCC，这里我还是按样例用的fbank，并且给予了26维度特征。要注意这里有一个FFT Size，如果超了的话需要在函数里加入nfft参数，默认是512，我在处理时改为了2048

得到矩阵之后，正常的思路应该是类似图片识别，进行CNN。这里我为了先试探一下，直接降维+SVM

# 降维

假设 each_mat 是其中一个.wav文件的特征，它的shape肯定是(rows, 26)的，我们将其转置后，降维到(26, 1)

降维方法要么PCA，要么TSNE，这里直接PCA降到一维，sklearn直接莽。

```
data_pca = PCA(n_components=1).fit_transform(each_mat)
```
拿到data_pca之后，结合标签，再结合大量的.wav文件，形成一个很大的矩阵，假设叫Voice, 这个Voice的shape是(m, 27)的，m表示有多少个训练wav，27表示第一列是标签，后面26是提取并降维后的数据。

Voice大概形态如下表：

tag | feat1 | feat2 | ... | feat26 |
----|------|-------|------|-------|
'angry' | num | num | ... | num |
'neutral' | num | num | ... | num |
'surprise' | num | num | ... | num |

# SVM

这里情绪标签有六种：['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise']

所以用一堆SVM进行六分类也行，用sklearn提供的OneVsRestClassifier也可以

训练核心很简单，就四行：

```
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import LinearSVC

clf = OneVsRestClassifier(LinearSVC(random_state=233))
clf.fit(X_train, rd.y_train)

```

最后访问一下两个集合上的准确率：

```
print(clf.score(X_train, rd.y_train))
print(clf.score(X_test, rd.y_test))
```

最后的效果是在训练集上60%, 测试集上46%，效果比较差，想也能想明白，不应该直接降维，应该用CNN提取特征，明天用CNN来提取再分类

